{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1i_oB7RtfDWRPtGK5CT_L5ghtrjjudihT","authorship_tag":"ABX9TyMdwW/vf/3JbjHiDkWRvBc1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8kjBGXQXKIrq"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization\n","from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import Input, Flatten, Dropout\n","from tensorflow.keras.layers import concatenate, Activation\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.utils import to_categorical\n","import os\n","import numpy as np\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKTn1xL2KyDS"},"source":["#load MNIST dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TONfhjnlK-PM"},"source":["#convert to one-hot vector\n","num_labels = len((np.unique(y_train)))\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nPN5ueiCh1M"},"source":["def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IcKLxEaLQn0"},"source":["#reshape and normalize input images\n","image_size = x_train.shape[1]\n","x_train = x_train.reshape(-1, image_size, image_size, 1)\n","x_test = x_test.reshape(-1, image_size, image_size, 1)\n","x_train = x_train.astype('float32')/255\n","x_test = x_test.astype('float32')/255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caSGsM_tLuCk"},"source":["#network parameters\n","input_shape = (image_size, image_size, 1)\n","batch_size = 128\n","kernel_size = 3\n","filters = 64\n","dropout = 0.3\n","data_augmentation = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLNDV3HeL9ay"},"source":["#use functional API to build CNN layers\n","inputs = Input(shape=input_shape)\n","y = Conv2D(filters=filters,\n","           kernel_size=kernel_size,\n","           activation='relu')(inputs)\n","y = MaxPool2D(2)(y)\n","y = Conv2D(filters=filters,\n","           kernel_size=kernel_size,\n","           activation='relu')(y)\n","y = MaxPool2D(2)(y)\n","y = Conv2D(filters=filters,\n","           kernel_size=kernel_size,\n","           activation='relu')(y)\n","#image to vector before connecting to dense layer\n","y = Flatten()(y)\n","#dropout regularization\n","y = Dropout(dropout)(y)\n","outputs = Dense(num_labels, activation='softmax')(y)\n","#build the model bu supplying inputs/outputs\n","model = Model(inputs=inputs, outputs=outputs)\n","#network model in text\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUEmAqvENGeH"},"source":["model_json = model.to_json()\n","with open(\"model.json\", \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VugoaMO5NA8F"},"source":["#classifier loss, adam optimizer, classifier accuracy\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtd1k58ACHJv"},"source":["# prepare model model saving directory\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'cifar10_densenet_model.{epoch:02d}.h5'\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","filepath = os.path.join(save_dir, model_name)\n","\n","# prepare callbacks for model saving and for learning rate reducer\n","checkpoint = ModelCheckpoint(filepath=filepath,\n","                             monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True)\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiO2olH4Cq9a"},"source":["# run training, with or without data augmentation\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=20,\n","              validation_data=(x_test, y_test),\n","              shuffle=True,\n","              callbacks=callbacks)\n","else:\n","    print('Using real-time data augmentation.')\n","    # preprocessing  and realtime data augmentation\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n","        width_shift_range=0.1,  # randomly shift images horizontally\n","        height_shift_range=0.1,  # randomly shift images vertically\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","    # compute quantities required for featurewise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied)\n","    datagen.fit(x_train)\n","\n","    steps_per_epoch = math.ceil(len(x_train) / batch_size)\n","    # fit the model on the batches generated by datagen.flow().\n","    model.fit(x=datagen.flow(x_train, y_train, batch_size=batch_size),\n","              verbose=1,\n","              epochs=20,\n","              validation_data=(x_test, y_test),\n","              steps_per_epoch=steps_per_epoch,\n","              callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopPPjEVOKC7"},"source":["#model accuracy on test dataset\n","score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n","print('Test accuracy : %.2f%%' %(100.0*score[1]))"],"execution_count":null,"outputs":[]}]}